# GENETARED BY NNDCT, DO NOT EDIT!

import torch
from torch import tensor
import pytorch_nndct as py_nndct

class WrappedModel(py_nndct.nn.NndctQuantModel):
    def __init__(self):
        super(WrappedModel, self).__init__()
        self.module_0 = py_nndct.nn.Input() #WrappedModel::input_0(WrappedModel::nndct_input_0)
        self.module_1 = py_nndct.nn.quant_input() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/QuantStub[quant_stub]/4774(WrappedModel::nndct_quant_stub_1)
        self.module_2 = py_nndct.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=[7, 7], stride=[2, 2], padding=[3, 3], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Conv2d[conv1]/ret.5(WrappedModel::nndct_conv2d_2)
        self.module_3 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/ReLU[relu]/4805(WrappedModel::nndct_relu_3)
        self.module_4 = py_nndct.nn.MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=[1, 1], ceil_mode=False) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/MaxPool2d[maxpool]/ret.9(WrappedModel::nndct_maxpool_4)
        self.module_5 = py_nndct.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[0]/Conv2d[conv1]/ret.11(WrappedModel::nndct_conv2d_5)
        self.module_6 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[0]/ReLU[relu]/4848(WrappedModel::nndct_relu_6)
        self.module_7 = py_nndct.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[0]/Conv2d[conv2]/ret.15(WrappedModel::nndct_conv2d_7)
        self.module_8 = py_nndct.nn.add() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[0]/Add[wrapped_Tensor___iadd___1]/ret.19(WrappedModel::nndct_elemwise_add_8)
        self.module_9 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[0]/ReLU[relu]/4879(WrappedModel::nndct_relu_9)
        self.module_10 = py_nndct.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[1]/Conv2d[conv1]/ret.21(WrappedModel::nndct_conv2d_10)
        self.module_11 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[1]/ReLU[relu]/4907(WrappedModel::nndct_relu_11)
        self.module_12 = py_nndct.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[1]/Conv2d[conv2]/ret.25(WrappedModel::nndct_conv2d_12)
        self.module_13 = py_nndct.nn.add() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[1]/Add[wrapped_Tensor___iadd___1]/ret.29(WrappedModel::nndct_elemwise_add_13)
        self.module_14 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer1]/BasicBlock[1]/ReLU[relu]/4938(WrappedModel::nndct_relu_14)
        self.module_15 = py_nndct.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[0]/Conv2d[conv1]/ret.31(WrappedModel::nndct_conv2d_15)
        self.module_16 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[0]/ReLU[relu]/4966(WrappedModel::nndct_relu_16)
        self.module_17 = py_nndct.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[0]/Conv2d[conv2]/ret.35(WrappedModel::nndct_conv2d_17)
        self.module_18 = py_nndct.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=[1, 1], stride=[2, 2], padding=[0, 0], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]/ret.39(WrappedModel::nndct_conv2d_18)
        self.module_19 = py_nndct.nn.add() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[0]/Add[wrapped_Tensor___iadd___1]/ret.43(WrappedModel::nndct_elemwise_add_19)
        self.module_20 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[0]/ReLU[relu]/5024(WrappedModel::nndct_relu_20)
        self.module_21 = py_nndct.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[1]/Conv2d[conv1]/ret.45(WrappedModel::nndct_conv2d_21)
        self.module_22 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[1]/ReLU[relu]/5052(WrappedModel::nndct_relu_22)
        self.module_23 = py_nndct.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[1]/Conv2d[conv2]/ret.49(WrappedModel::nndct_conv2d_23)
        self.module_24 = py_nndct.nn.add() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[1]/Add[wrapped_Tensor___iadd___1]/ret.53(WrappedModel::nndct_elemwise_add_24)
        self.module_25 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer2]/BasicBlock[1]/ReLU[relu]/5083(WrappedModel::nndct_relu_25)
        self.module_26 = py_nndct.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[0]/Conv2d[conv1]/ret.55(WrappedModel::nndct_conv2d_26)
        self.module_27 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[0]/ReLU[relu]/5111(WrappedModel::nndct_relu_27)
        self.module_28 = py_nndct.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[0]/Conv2d[conv2]/ret.59(WrappedModel::nndct_conv2d_28)
        self.module_29 = py_nndct.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=[1, 1], stride=[2, 2], padding=[0, 0], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]/ret.63(WrappedModel::nndct_conv2d_29)
        self.module_30 = py_nndct.nn.add() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[0]/Add[wrapped_Tensor___iadd___1]/ret.67(WrappedModel::nndct_elemwise_add_30)
        self.module_31 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[0]/ReLU[relu]/5169(WrappedModel::nndct_relu_31)
        self.module_32 = py_nndct.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[1]/Conv2d[conv1]/ret.69(WrappedModel::nndct_conv2d_32)
        self.module_33 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[1]/ReLU[relu]/5197(WrappedModel::nndct_relu_33)
        self.module_34 = py_nndct.nn.Conv2d(in_channels=256, out_channels=256, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[1]/Conv2d[conv2]/ret.73(WrappedModel::nndct_conv2d_34)
        self.module_35 = py_nndct.nn.add() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[1]/Add[wrapped_Tensor___iadd___1]/ret.77(WrappedModel::nndct_elemwise_add_35)
        self.module_36 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer3]/BasicBlock[1]/ReLU[relu]/5228(WrappedModel::nndct_relu_36)
        self.module_37 = py_nndct.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=[3, 3], stride=[2, 2], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[0]/Conv2d[conv1]/ret.79(WrappedModel::nndct_conv2d_37)
        self.module_38 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[0]/ReLU[relu]/5256(WrappedModel::nndct_relu_38)
        self.module_39 = py_nndct.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[0]/Conv2d[conv2]/ret.83(WrappedModel::nndct_conv2d_39)
        self.module_40 = py_nndct.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=[1, 1], stride=[2, 2], padding=[0, 0], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]/ret.87(WrappedModel::nndct_conv2d_40)
        self.module_41 = py_nndct.nn.add() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[0]/Add[wrapped_Tensor___iadd___1]/ret.91(WrappedModel::nndct_elemwise_add_41)
        self.module_42 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[0]/ReLU[relu]/5314(WrappedModel::nndct_relu_42)
        self.module_43 = py_nndct.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[1]/Conv2d[conv1]/ret.93(WrappedModel::nndct_conv2d_43)
        self.module_44 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[1]/ReLU[relu]/5342(WrappedModel::nndct_relu_44)
        self.module_45 = py_nndct.nn.Conv2d(in_channels=512, out_channels=512, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1], dilation=[1, 1], groups=1, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[1]/Conv2d[conv2]/ret.97(WrappedModel::nndct_conv2d_45)
        self.module_46 = py_nndct.nn.add() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[1]/Add[wrapped_Tensor___iadd___1]/ret.101(WrappedModel::nndct_elemwise_add_46)
        self.module_47 = py_nndct.nn.ReLU(inplace=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Sequential[layer4]/BasicBlock[1]/ReLU[relu]/5373(WrappedModel::nndct_relu_47)
        self.module_48 = py_nndct.nn.AdaptiveAvgPool2d(output_size=[1, 1]) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/AdaptiveAvgPool2d[avgpool]/5390(WrappedModel::nndct_adaptive_avg_pool2d_48)
        self.module_49 = py_nndct.nn.Module('nndct_flatten') #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/ret.103(WrappedModel::nndct_flatten_49)
        self.module_50 = py_nndct.nn.Linear(in_features=512, out_features=1000, bias=True) #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/ResNet[_model]/Linear[fc]/ret.105(WrappedModel::nndct_dense_50)
        self.module_51 = py_nndct.nn.dequant_output() #WrappedModel::WrappedModel/ModelWithQuantStub[_inner_model]/DeQuantStub[dequant_stub]/5398(WrappedModel::nndct_dequant_stub_51)

    @py_nndct.nn.forward_processor
    def forward(self, *args):
        output_module_0 = self.module_0(input=args[0])
        output_module_0 = self.module_1(input=output_module_0)
        output_module_0 = self.module_2(output_module_0)
        output_module_0 = self.module_3(output_module_0)
        output_module_0 = self.module_4(output_module_0)
        output_module_5 = self.module_5(output_module_0)
        output_module_5 = self.module_6(output_module_5)
        output_module_5 = self.module_7(output_module_5)
        output_module_5 = self.module_8(input=output_module_5, other=output_module_0, alpha=1)
        output_module_5 = self.module_9(output_module_5)
        output_module_10 = self.module_10(output_module_5)
        output_module_10 = self.module_11(output_module_10)
        output_module_10 = self.module_12(output_module_10)
        output_module_10 = self.module_13(input=output_module_10, other=output_module_5, alpha=1)
        output_module_10 = self.module_14(output_module_10)
        output_module_15 = self.module_15(output_module_10)
        output_module_15 = self.module_16(output_module_15)
        output_module_15 = self.module_17(output_module_15)
        output_module_18 = self.module_18(output_module_10)
        output_module_15 = self.module_19(input=output_module_15, other=output_module_18, alpha=1)
        output_module_15 = self.module_20(output_module_15)
        output_module_21 = self.module_21(output_module_15)
        output_module_21 = self.module_22(output_module_21)
        output_module_21 = self.module_23(output_module_21)
        output_module_21 = self.module_24(input=output_module_21, other=output_module_15, alpha=1)
        output_module_21 = self.module_25(output_module_21)
        output_module_26 = self.module_26(output_module_21)
        output_module_26 = self.module_27(output_module_26)
        output_module_26 = self.module_28(output_module_26)
        output_module_29 = self.module_29(output_module_21)
        output_module_26 = self.module_30(input=output_module_26, other=output_module_29, alpha=1)
        output_module_26 = self.module_31(output_module_26)
        output_module_32 = self.module_32(output_module_26)
        output_module_32 = self.module_33(output_module_32)
        output_module_32 = self.module_34(output_module_32)
        output_module_32 = self.module_35(input=output_module_32, other=output_module_26, alpha=1)
        output_module_32 = self.module_36(output_module_32)
        output_module_37 = self.module_37(output_module_32)
        output_module_37 = self.module_38(output_module_37)
        output_module_37 = self.module_39(output_module_37)
        output_module_40 = self.module_40(output_module_32)
        output_module_37 = self.module_41(input=output_module_37, other=output_module_40, alpha=1)
        output_module_37 = self.module_42(output_module_37)
        output_module_43 = self.module_43(output_module_37)
        output_module_43 = self.module_44(output_module_43)
        output_module_43 = self.module_45(output_module_43)
        output_module_43 = self.module_46(input=output_module_43, other=output_module_37, alpha=1)
        output_module_43 = self.module_47(output_module_43)
        output_module_43 = self.module_48(output_module_43)
        output_module_43 = self.module_49(input=output_module_43, start_dim=1, end_dim=-1)
        output_module_43 = self.module_50(output_module_43)
        output_module_43 = self.module_51(input=output_module_43)
        return output_module_43
